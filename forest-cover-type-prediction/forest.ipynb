{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Read Data ###\n",
    "df = pd.read_csv('data/train.csv')\n",
    "#### Check Null Data ###\n",
    "if df[df.isnull().any(axis=1) == True].shape[0] != 0:\n",
    "    print('Warning, null data present')\n",
    "\n",
    "### Transform / Wrangle Data ###\n",
    "X_train = df.iloc[:, :-1]\n",
    "Y_train = df.iloc[:, -1]\n",
    "\n",
    "X_test = pd.read_csv('data/test.csv')\n",
    "X_test_ids = X_test.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Classes/Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransformer(TransformerMixin):\n",
    "    '''\n",
    "    Helper class for transforming input dataframes into desired input features. \n",
    "    Implements the feature engineering logic.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        ignore_cols = ['Id']\n",
    "        for col in X.columns:\n",
    "            if X[col].std() == 0:\n",
    "                print('Columns to drop: {}, std={}'.format(col, X[col].std()))\n",
    "                ignore_cols.append(col)\n",
    "        self.ignore_cols = ignore_cols\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        self.__clean_columns(X)\n",
    "        return X\n",
    "\n",
    "    def __clean_columns(self, X):\n",
    "        drop_cols = self.ignore_cols\n",
    "        for col in drop_cols:\n",
    "            if col not in X.columns:\n",
    "                drop_cols.remove(col)\n",
    "        X.drop(labels=self.ignore_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_results(estimator, X_test, X_test_ids):\n",
    "    '''\n",
    "    Helper function for predicting and saving test results\n",
    "    '''\n",
    "    Y_Pred = pd.DataFrame(estimator.predict(X_test), columns=['Cover_Type'])\n",
    "    results = pd.concat([X_test_ids, Y_Pred], axis=1)\n",
    "    results.to_csv('data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(estimator, X):\n",
    "    return pd.DataFrame(\n",
    "        np.array([X.columns, estimator.feature_importances_]).T, \n",
    "        columns=['Features', 'Importance']\n",
    "    ).sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop: Soil_Type7, std=0.0\n",
      "Columns to drop: Soil_Type15, std=0.0\n"
     ]
    }
   ],
   "source": [
    "feature_transformer = FeatureTransformer()\n",
    "X_train = feature_transformer.fit_transform(X_train)\n",
    "X_test = feature_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type31  Soil_Type32  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type33  Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type38  Soil_Type39  Soil_Type40  \n",
       "0            0            0            0  \n",
       "1            0            0            0  \n",
       "2            0            0            0  \n",
       "3            0            0            0  \n",
       "4            0            0            0  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using of Plain Single Algorithm Approaches\n",
    "1. LogisticRegression\n",
    "2. SVC\n",
    "3. ExtraTreesClassifier\n",
    "4. RandomForestClassifier\n",
    "5. LGBMClassifier\n",
    "6. XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. LogisticRegression\n",
    "<i>Approach not chosen as many iterations needed for convergence</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lrc = LogisticRegression()\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_jobs': [2],\n",
    "        'solver': ['lbfgs', 'saga'],\n",
    "        'tol': [1e-4, 1e-5],\n",
    "        'C': [0.5, 1, 5],\n",
    "        'multi_class': ['auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(estimator=lrc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=2)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)\n",
    "\n",
    "lrc = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svc = SVC()\n",
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'tol': [1e-4, 0.001],\n",
    "        'C': [0.5, 1, 5],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=2)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)\n",
    "\n",
    "svc = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rfc = RandomForestClassifier()\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_jobs': [2],\n",
    "        'criterion': ['gini', 'entropy'], \n",
    "        'n_estimators': [200, 500, 700], \n",
    "        'max_depth': [3, 15, 30, None],\n",
    "        'max_features': [0.3, 0.6, 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=2)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)\n",
    "\n",
    "rfc = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "etc = ExtraTreesClassifier()\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_jobs': [2],\n",
    "        'criterion': ['gini', 'entropy'], \n",
    "        'n_estimators': [200, 500, 700], \n",
    "        'max_depth': [3, 15, 30, None],\n",
    "        'max_features': [0.3, 0.6, 'auto']\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(estimator=etc, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=2)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)\n",
    "\n",
    "etc = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  0:39:27.639839 ms\n",
      "LBGM Best Params:  {'learning_rate': 0.15, 'max_depth': -1, 'n_estimators': 250, 'n_jobs': 4, 'num_leaves': 67, 'reg_lambda': 0}\n",
      "LBGM Best Score:  0.7972222222222223\n",
      "Wall time: 39min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgbmc = LGBMClassifier()\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_jobs': [4],\n",
    "        'max_depth': [2, 3, -1], \n",
    "        'n_estimators': [150, 200, 250], \n",
    "        'num_leaves': [31, 45, 63, 67],\n",
    "        'learning_rate': [0.15, 0.2, 0.25],\n",
    "        'reg_lambda': [0, 1.5]\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(estimator=lgbmc, param_grid=param_grid, n_jobs=4, scoring='accuracy', cv=5)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)\n",
    "\n",
    "lgbmc = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. XGBClassifier\n",
    "<i>XGBoost Best Params:  {'max_depth': 2, 'n_estimators': 50, 'n_threads': 4, 'reg_lambda': 1.6, 'tree_method': 'hist'}\n",
    "XGBoost Best Score:  0.658531746031746</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgbc = XGBClassifier()\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_jobs': [4],\n",
    "        'max_depth': [2, 3, 10, len(X_train.columns)],\n",
    "        'n_estimators': [50, 100, 200], \n",
    "        'reg_lambda': [0, 1.6]\n",
    "    }\n",
    "]\n",
    "\n",
    "gscv = GridSearchCV(estimator=xgbc, param_grid=param_grid, n_jobs=4, scoring='accuracy', cv=5)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)\n",
    "\n",
    "xgbc = gscv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Classifiers of Each Algorithm Tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommy.yong\\AppData\\Local\\Continuum\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\tommy.yong\\AppData\\Local\\Continuum\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\tommy.yong\\AppData\\Local\\Continuum\\anaconda3\\envs\\learnenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy:  [0.47579365 0.39702381 0.44623016]\n",
      "SVC Accuracy:  [0.57460317 0.58611111 0.61607143]\n",
      "RandomForestClassifier Accuracy:  [0.80079365 0.77301587 0.78571429]\n",
      "ExtraTreesClassifier Accuracy:  [0.80992063 0.78075397 0.78551587]\n",
      "LGBMClassifier Accuracy:  [0.80615079 0.77757937 0.76170635]\n",
      "XGBClassifier Accuracy:  [0.6390873  0.65575397 0.6890873 ]\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lrc = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "svc = SVC(gamma='scale')\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_features=0.6, n_estimators=500)\n",
    "etc = ExtraTreesClassifier(criterion='entropy', max_features=0.6, n_estimators=500)\n",
    "lgbmc = LGBMClassifier(learning_rate=0.2, n_estimators=200, num_leaves=63)\n",
    "xgbc = XGBClassifier(max_depth=2, n_estimators=50, reg_lambda=1.6, tree_method='hist')\n",
    "\n",
    "print('LogisticRegression Accuracy: ', cross_val_score(estimator=lrc, X=X_train, y=Y_train, scoring='accuracy', cv=3))\n",
    "print('SVC Accuracy: ', cross_val_score(estimator=svc, X=X_train, y=Y_train, scoring='accuracy', cv=3))\n",
    "print('RandomForestClassifier Accuracy: ', cross_val_score(estimator=rfc, X=X_train, y=Y_train, scoring='accuracy', cv=3))\n",
    "print('ExtraTreesClassifier Accuracy: ', cross_val_score(estimator=etc, X=X_train, y=Y_train, scoring='accuracy', cv=3))\n",
    "print('LGBMClassifier Accuracy: ', cross_val_score(estimator=lgbmc, X=X_train, y=Y_train, scoring='accuracy', cv=3))\n",
    "print('XGBClassifier Accuracy: ', cross_val_score(estimator=xgbc, X=X_train, y=Y_train, scoring='accuracy', cv=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>ExtraTreesClassifier works best here</strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "etc = ExtraTreesClassifier(criterion='entropy', max_features=0.6, n_estimators=500)\n",
    "# Fitting best estimator\n",
    "etc.fit(X_train, Y_train)\n",
    "# Predicting and getting output prediction file\n",
    "predict_results(estimator=etc, X_test=X_test, X_test_ids=X_test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score:\n",
    "* <strong style=\"color: green\">ExtraTreesClassifier - 0.78275</strong>\n",
    "* RandomForestClassifier - 0.75646\n",
    "* LGBMClassifier - 0.76851\n",
    "* XGBClassifier - 0.58489"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevation</td>\n",
       "      <td>0.2996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wilderness_Area4</td>\n",
       "      <td>0.145852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horizontal_Distance_To_Roadways</td>\n",
       "      <td>0.0646923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Horizontal_Distance_To_Fire_Points</td>\n",
       "      <td>0.0516294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horizontal_Distance_To_Hydrology</td>\n",
       "      <td>0.0463148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vertical_Distance_To_Hydrology</td>\n",
       "      <td>0.0335986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hillshade_9am</td>\n",
       "      <td>0.029792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aspect</td>\n",
       "      <td>0.0296198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wilderness_Area1</td>\n",
       "      <td>0.0295801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hillshade_Noon</td>\n",
       "      <td>0.0270735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features Importance\n",
       "0                            Elevation     0.2996\n",
       "13                    Wilderness_Area4   0.145852\n",
       "5      Horizontal_Distance_To_Roadways  0.0646923\n",
       "9   Horizontal_Distance_To_Fire_Points  0.0516294\n",
       "3     Horizontal_Distance_To_Hydrology  0.0463148\n",
       "4       Vertical_Distance_To_Hydrology  0.0335986\n",
       "6                        Hillshade_9am   0.029792\n",
       "1                               Aspect  0.0296198\n",
       "10                    Wilderness_Area1  0.0295801\n",
       "7                       Hillshade_Noon  0.0270735"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_importances(etc, X_train).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Part: Exploring Ensemble Methods\n",
    "### Variables are split and grouped in 4 segments:\n",
    "#### 1) Soil Group Vars --> RFC to get proba\n",
    "#### 2) Wilderness Area Group Vars --> RFC to get proba\n",
    "#### 3) Inclination Group Vars --> RFC or LGBMC to get proba\n",
    "#### 4) Spatial Group Vars --> LGBMC to get proba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Study\n",
    "### Prepare Group Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
      "       'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
      "       'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
      "       'Horizontal_Distance_To_Fire_Points', 'Wilderness_Area1',\n",
      "       'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4',\n",
      "       'Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
      "       'Soil_Type6', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n",
      "       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type16',\n",
      "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
      "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
      "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
      "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
      "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
      "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40',\n",
      "       'Distance_To_Hydrology'],\n",
      "      dtype='object')\n",
      "(53,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.columns)\n",
    "print(X_train.columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_soil = X_train.loc[:, ['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "       'Soil_Type6', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n",
    "       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']]\n",
    "X_wild_area = X_train.loc[:, ['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']]\n",
    "X_incline = X_train.loc[:, ['Aspect', 'Slope', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']]\n",
    "X_spatial = X_train.loc[:, ['Elevation', 'Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology', \n",
    "                      'Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']]\n",
    "\n",
    "X_soil_test = X_test.loc[:, ['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "       'Soil_Type6', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n",
    "       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']]\n",
    "X_wild_area_test = X_test.loc[:, ['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']]\n",
    "X_incline_test = X_test.loc[:, ['Aspect', 'Slope', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']]\n",
    "X_spatial_test = X_test.loc[:, ['Elevation', 'Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology', \n",
    "                      'Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Soil Group Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Soil Best Params:  {'criterion': 'entropy', 'max_depth': None, 'n_estimators': 100, 'n_jobs': 6}\n",
      "RFC Soil Best Score:  -1.1320652559358413\n",
      "CPU times: user 1min, sys: 5.76 s, total: 1min 5s\n",
      "Wall time: 25.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Soil Type RF Classifier ###\n",
    "rfc_soil = RandomForestClassifier()\n",
    "#### Perform GridSearchCV to optimize params ####\n",
    "rfc_soil_param_grid = [\n",
    "    {\n",
    "        'n_jobs': [6],\n",
    "        'n_estimators': [10, 100, 150],\n",
    "        'max_depth': [3, 5, None],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "]\n",
    "\n",
    "rfc_gscv = GridSearchCV(\n",
    "    estimator=rfc_soil, \n",
    "    param_grid=rfc_soil_param_grid, \n",
    "    scoring='neg_log_loss', \n",
    "    cv=5, n_jobs=6\n",
    ")\n",
    "rfc_gscv.fit(X_soil, Y)\n",
    "\n",
    "print('RFC Soil Best Params: ', rfc_gscv.best_params_)\n",
    "print('RFC Soil Best Score: ', rfc_gscv.best_score_)\n",
    "\n",
    "#### Get best estimator and predict proba ####\n",
    "rfc_soil = rfc_gscv.best_estimator_\n",
    "Y_proba_soil_test = rfc_soil.predict_proba(X_soil_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Wilderness Area Group Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Soil Best Params:  {'criterion': 'gini', 'max_depth': None, 'n_estimators': 100, 'n_jobs': 6}\n",
      "RFC Soil Best Score:  -1.463986775287638\n",
      "CPU times: user 12.1 s, sys: 21 s, total: 33 s\n",
      "Wall time: 8.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Wilderness Area RF Classifier ###\n",
    "rfc_wild_area = RandomForestClassifier()\n",
    "#### Perform GridSearchCV to optimize params ####\n",
    "rfc_wild_area_param_grid = [\n",
    "    {\n",
    "        'n_jobs': [6],\n",
    "        'n_estimators': [75, 100, 125],\n",
    "        'max_depth': [2, None],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "]\n",
    "\n",
    "rfc_wild_area_gscv = GridSearchCV(\n",
    "    estimator=rfc_wild_area, \n",
    "    param_grid=rfc_wild_area_param_grid, \n",
    "    scoring='neg_log_loss', \n",
    "    cv=5, n_jobs=6\n",
    ")\n",
    "rfc_wild_area_gscv.fit(X_wild_area, Y)\n",
    "\n",
    "print('RFC Wilderness Best Params: ', rfc_wild_area_gscv.best_params_)\n",
    "print('RFC Wilderness Best Score: ', rfc_wild_area_gscv.best_score_)\n",
    "\n",
    "#### Get best estimator and predict proba ####\n",
    "rfc_wild_area = rfc_wild_area_gscv.best_estimator_\n",
    "Y_proba_wild_area_test = rfc_wild_area.predict_proba(X_wild_area_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inclination Group Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Soil Best Params:  {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 150, 'n_jobs': 6}\n",
      "RFC Soil Best Score:  -1.8064450894245248\n",
      "CPU times: user 22.6 s, sys: 36 s, total: 58.6 s\n",
      "Wall time: 32.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Inclination RF Classifier ###\n",
    "rfc_incline = RandomForestClassifier()\n",
    "#### Perform GridSearchCV to optimize params ####\n",
    "rfc_incline_param_grid = [\n",
    "    {\n",
    "        'n_jobs': [6],\n",
    "        'n_estimators': [10, 100, 150, 200],\n",
    "        'max_depth': [3, 5, None],\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "]\n",
    "\n",
    "rfc_incline_gscv = GridSearchCV(\n",
    "    estimator=rfc_incline, \n",
    "    param_grid=rfc_incline_param_grid, \n",
    "    scoring='neg_log_loss', \n",
    "    cv=5, n_jobs=6\n",
    ")\n",
    "rfc_incline_gscv.fit(X_incline, Y)\n",
    "\n",
    "print('RFC Inclination Best Params: ', rfc_incline_gscv.best_params_)\n",
    "print('RFC Inclination Best Score: ', rfc_incline_gscv.best_score_)\n",
    "\n",
    "#### Get best estimator and predict proba ####\n",
    "rfc_incline = rfc_incline_gscv.best_estimator_\n",
    "Y_proba_incline_test = rfc_incline.predict_proba(X_incline_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Spatial Group Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lgbmc Soil Best Params:  {'learning_rate': 0.125, 'n_estimators': 200, 'n_jobs': 6, 'num_leaves': 65}\n",
      "lgbmc Soil Best Score:  -0.8667188561279542\n",
      "CPU times: user 1min 35s, sys: 411 ms, total: 1min 35s\n",
      "Wall time: 30min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Inclination RF Classifier ###\n",
    "lgbmc_spatial = LGBMClassifier()\n",
    "#### Perform GridSearchCV to optimize params ####\n",
    "lgbmc_spatial_param_grid = [\n",
    "    {\n",
    "        'n_jobs': [6],\n",
    "        'n_estimators': [200, 250, 275],\n",
    "        'learning_rate': [0.125, 0.15, 0.175, 0.2],\n",
    "        'num_leaves': [65, 67, 70]\n",
    "    }\n",
    "]\n",
    "\n",
    "lgbmc_spatial_gscv = GridSearchCV(\n",
    "    estimator=lgbmc_spatial, \n",
    "    param_grid=lgbmc_spatial_param_grid, \n",
    "    scoring='neg_log_loss', \n",
    "    cv=5, n_jobs=6\n",
    ")\n",
    "lgbmc_spatial_gscv.fit(X_spatial, Y)\n",
    "\n",
    "print('LGBMC Spatial Best Params: ', lgbmc_spatial_gscv.best_params_)\n",
    "print('LGBMC Spatial Best Score: ', lgbmc_spatial_gscv.best_score_)\n",
    "\n",
    "#### Get best estimator and predict proba ####\n",
    "lgbmc_spatial = lgbmc_spatial_gscv.best_estimator_\n",
    "Y_proba_spatial_test = lgbmc_spatial.predict_proba(X_spatial_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get final prediction\n",
    "### Methods:\n",
    "* 1) Get weights for group vars, and use softmax to derive final probabilities + one-hot class for final prediction\n",
    "* 2) Build another ensemble estimator from the other estimators, and make final prediction\n",
    "* 3) TODO: find out ways to feed group vars outputs as intermediate inputs, and feed to another estimator for making final prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Weights for each output\n",
    "### i) Prepare wrapper classes for each classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentClassifier(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, classifier, columns):\n",
    "        self.classifier = classifier\n",
    "        self.columns = columns\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X = X.loc[:, self.columns]\n",
    "        self.classifier.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = X.loc[:, self.columns]\n",
    "        return self.classifier.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        X = X.loc[:, self.columns]\n",
    "        return self.classifier.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "soil_classifier = SegmentClassifier(\n",
    "    classifier=RandomForestClassifier(criterion='entropy', n_estimators=100, n_jobs=4),\n",
    "    columns=['Soil_Type1', 'Soil_Type2', 'Soil_Type3', 'Soil_Type4', 'Soil_Type5',\n",
    "       'Soil_Type6', 'Soil_Type8', 'Soil_Type9', 'Soil_Type10', 'Soil_Type11',\n",
    "       'Soil_Type12', 'Soil_Type13', 'Soil_Type14', 'Soil_Type16',\n",
    "       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n",
    "       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n",
    "       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n",
    "       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n",
    "       'Soil_Type33', 'Soil_Type34', 'Soil_Type35', 'Soil_Type36',\n",
    "       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']\n",
    ")\n",
    "\n",
    "wild_area_classifier = SegmentClassifier(\n",
    "    classifier=RandomForestClassifier(criterion='gini', n_estimators=100, n_jobs=4),\n",
    "    columns=['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3', 'Wilderness_Area4']\n",
    ")\n",
    "\n",
    "incline_classifier = SegmentClassifier(\n",
    "    classifier=RandomForestClassifier(criterion='entropy', n_estimators=150, max_depth=5, n_jobs=4),\n",
    "    columns=['Aspect', 'Slope', 'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm']\n",
    ")\n",
    "\n",
    "spatial_classifier = SegmentClassifier(\n",
    "    classifier=LGBMClassifier(learning_rate=0.125, n_estimators=200, num_leaves=65, n_jobs=4),\n",
    "    columns=['Elevation', 'Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology', \n",
    "                      'Horizontal_Distance_To_Roadways','Horizontal_Distance_To_Fire_Points']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('soil_classifier', soil_classifier),\n",
    "        ('wild_area_classifier', wild_area_classifier),\n",
    "        ('incline_classifier', incline_classifier),\n",
    "        ('spatial_classifier', spatial_classifier)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC Inclination Best Params:  {'voting': 'soft', 'weights': [1, 2, 3, 4]}\n",
      "RFC Inclination Best Score:  0.7231481481481481\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = [\n",
    "    {\n",
    "        'voting': ['soft', 'hard'],\n",
    "        'weights': [[1,1,2,16], [1,2,3,4], [1,1,4,10]]\n",
    "    }\n",
    "]\n",
    "gscv = GridSearchCV(ensemble_classifier, param_grid=param_grid, n_jobs=4, cv=5)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results(estimator=gscv.best_estimator_, X_test=X_test, X_test_ids=X_test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score: 0.69541"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is lower than the single <strong>LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
    "               importance_type='split', learning_rate=0.15, max_depth=-1,\n",
    "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
    "               n_estimators=250, n_jobs=6, num_leaves=70, objective=None,\n",
    "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
    "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)</strong>.\n",
    "               \n",
    "How about ensembling the single classifier with the ensemble classifier above?\n",
    "\n",
    "* Method 1 => Use the 4 SegmentClassifiers + 1 LGBMClassifier in 1 VotingClassifier\n",
    "* Method 2 => Use a new VotingClassifier with VotingClassifier from the SegmentClassifers + LGBMClassifer as estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method 1 ###\n",
    "ensemble_classifier = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('soil_classifier', soil_classifier),\n",
    "        ('wild_area_classifier', wild_area_classifier),\n",
    "        ('incline_classifier', incline_classifier),\n",
    "        ('spatial_classifier', spatial_classifier),\n",
    "        ('original_classifier', etc)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tommy.yong\\AppData\\Local\\Continuum\\anaconda3\\envs\\learnenv\\lib\\site-packages\\pandas\\core\\indexing.py:1404: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#deprecate-loc-reindex-listlike\n",
      "  return self._getitem_tuple(key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'voting': 'soft', 'weights': [0, 0, 0, 0, 1]}\n",
      "Best Score:  0.8029761904761905\n",
      "Wall time: 10min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = [\n",
    "    {\n",
    "        'voting': ['soft'],\n",
    "        'weights': [[1,1,2,3,5], [1,2,3,4,5], [0,0,0,0,1], [0,0,0,2,5]]\n",
    "#         'weights': [[0,0,0,3,5], [0,0,0,2,5]]\n",
    "    }\n",
    "]\n",
    "gscv = GridSearchCV(ensemble_classifier, param_grid=param_grid, n_jobs=2, cv=5)\n",
    "gscv.fit(X_train, Y_train)\n",
    "print('Best Params: ', gscv.best_params_)\n",
    "print('Best Score: ', gscv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_results(estimator=gscv.best_estimator_, X_test=X_test, X_test_ids=X_test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score (from earlier score of params = {'voting': 'soft', 'weights': [0, 0, 0, 0, 1]}: 0.76769):\n",
    "* params = {'voting': 'soft', 'weights': [1, 1, 2, 3, 5]}: 0.76706\n",
    "* params = {'voting': 'soft', 'weights': [0, 0, 2, 3, 5]}: 0.76787\n",
    "* params = {'voting': 'soft', 'weights': [0, 0, 0, 3, 5]}: 0.76817\n",
    "* params = {'voting': 'soft', 'weights': [0, 0, 0, 2, 5]}: 0.76866"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To try more complex feature engineering as approach to increase score (since ensemble does not increase the score much)\n",
    "# Feature Engineering Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out approach by https://www.kaggle.com/jianyu/my-first-submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureTransformer(TransformerMixin):\n",
    "    '''\n",
    "    Implementing __enhance_columns method to add more sophisticated features.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X):\n",
    "        ignore_cols = ['Id']\n",
    "        for col in X.columns:\n",
    "            if X[col].std() == 0:\n",
    "                print('Columns to drop: {}, std={}'.format(col, X[col].std()))\n",
    "                ignore_cols.append(col)\n",
    "        self.ignore_cols = ignore_cols\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        self.__clean_columns(X)\n",
    "        self.__enhance_columns(X)\n",
    "        return X\n",
    "\n",
    "    def __clean_columns(self, X):\n",
    "        drop_cols = self.ignore_cols\n",
    "        for col in drop_cols:\n",
    "            if col not in X.columns:\n",
    "                drop_cols.remove(col)\n",
    "        X.drop(labels=self.ignore_cols, axis=1, inplace=True)\n",
    "        \n",
    "    def __enhance_columns(self, X):\n",
    "        X.loc[:, 'Distance_To_Hydrology'] = (X.loc[:, 'Horizontal_Distance_To_Hydrology'] ** 2 \n",
    "            + X.loc[:, 'Vertical_Distance_To_Hydrology'] ** 2) ** 0.5\n",
    "        X.loc[:, 'Distance_To_Amenities_Avg'] = X.loc[:, [\n",
    "            'Horizontal_Distance_To_Hydrology', \n",
    "            'Horizontal_Distance_To_Roadways', \n",
    "            'Horizontal_Distance_To_Fire_Points'\n",
    "        ]].mean(axis=1)\n",
    "        X.loc[:, 'Elevation_Minus_Disthy'] = X.loc[:, 'Elevation'] - X.loc[:, 'Vertical_Distance_To_Hydrology']\n",
    "        X.loc[:, 'Elevation_Plus_Disthy'] = X.loc[:, 'Elevation'] + X.loc[:, 'Vertical_Distance_To_Hydrology']\n",
    "        X.loc[:, 'Disthx_Minus_Distfx'] = X.loc[:, 'Horizontal_Distance_To_Hydrology'] - X.loc[:, 'Horizontal_Distance_To_Fire_Points']\n",
    "        X.loc[:, 'Disthx_Plus_Distfx'] = X.loc[:, 'Horizontal_Distance_To_Hydrology'] + X.loc[:, 'Horizontal_Distance_To_Fire_Points']\n",
    "        X.loc[:, 'Disthx_Minus_Distrx'] = X.loc[:, 'Horizontal_Distance_To_Hydrology'] - X.loc[:, 'Horizontal_Distance_To_Roadways']\n",
    "        X.loc[:, 'Disthx_Plus_Distrx'] = X.loc[:, 'Horizontal_Distance_To_Hydrology'] + X.loc[:, 'Horizontal_Distance_To_Roadways']\n",
    "        X.loc[:, 'Distfx_Minus_Distrx'] = X.loc[:, 'Horizontal_Distance_To_Fire_Points'] - X.loc[:, 'Horizontal_Distance_To_Roadways']\n",
    "        X.loc[:, 'Distfx_Minus_Distrx'] = X.loc[:, 'Horizontal_Distance_To_Fire_Points'] - X.loc[:, 'Horizontal_Distance_To_Roadways']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns to drop: Soil_Type7, std=0.0\n",
      "Columns to drop: Soil_Type15, std=0.0\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "feature_transformer_new = FeatureTransformer()\n",
    "X_train = feature_transformer_new.fit_transform(X_train)\n",
    "X_test = feature_transformer_new.transform(X_test)\n",
    "\n",
    "etc = ExtraTreesClassifier(criterion='entropy', max_features=0.6, n_estimators=500)\n",
    "# Fitting best estimator\n",
    "etc.fit(X_train, Y_train)\n",
    "# Predicting and getting output prediction file\n",
    "predict_results(estimator=etc, X_test=X_test, X_test_ids=X_test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle Score: 0.80805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Elevation_Minus_Disthy</td>\n",
       "      <td>0.168964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elevation</td>\n",
       "      <td>0.157376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wilderness_Area4</td>\n",
       "      <td>0.109247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Elevation_Plus_Disthy</td>\n",
       "      <td>0.0824248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Distance_To_Amenities_Avg</td>\n",
       "      <td>0.0253563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Disthx_Minus_Distrx</td>\n",
       "      <td>0.0233074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Horizontal_Distance_To_Roadways</td>\n",
       "      <td>0.0231599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Distance_To_Hydrology</td>\n",
       "      <td>0.0228965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wilderness_Area1</td>\n",
       "      <td>0.0227343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Horizontal_Distance_To_Hydrology</td>\n",
       "      <td>0.0227193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Features Importance\n",
       "54            Elevation_Minus_Disthy   0.168964\n",
       "0                          Elevation   0.157376\n",
       "13                  Wilderness_Area4   0.109247\n",
       "55             Elevation_Plus_Disthy  0.0824248\n",
       "53         Distance_To_Amenities_Avg  0.0253563\n",
       "58               Disthx_Minus_Distrx  0.0233074\n",
       "5    Horizontal_Distance_To_Roadways  0.0231599\n",
       "52             Distance_To_Hydrology  0.0228965\n",
       "10                  Wilderness_Area1  0.0227343\n",
       "3   Horizontal_Distance_To_Hydrology  0.0227193"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_importances(etc, X_train).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
